{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK\n",
    "\n",
    "Natural Language Toolkit is a library for NLP tasks using Python. It provides easy-to-use\n",
    "interfaces, text corpora, and lexical resources. It can do classifications, tokenizations, stemmings, taggings, parsings, and sementic reasonings. In this starter file, we will be simply trying out the VADER Sentiment Analysis tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using NLTK's Pre-Trained Sentiment Analyzer. \n",
    "VADER(Valence Aware Dictionary and Sentiment Reasoner) is a pretrained NLTK analyzing model that is best suited for languages used in social media, those with short sentences with slang and abbreviations. Although they are less accurate when examining the more structured, essay-like sentences with longer length, they are useful beginning tools as they are pretrained with less overhead for getting initial results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/weilezheng/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"vader_lexicon\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " VADER is the sentiment analysis tool, the VADER Lexicon is the dictionary it uses, and the NLTK Sentiment Intensity Analyzer is the module in NLTK that uses VADER to perform sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.182, 'pos': 0.818, 'compound': 0.6696}\n",
      "{'neg': 0.0, 'neu': 0.308, 'pos': 0.692, 'compound': 0.6696}\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "print(analyzer.polarity_scores(\"Love you!\"))\n",
    "print(analyzer.polarity_scores(\"I love data science!\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative, neutral, and positive scores are normalized to add up to 1. Compound score are normalized to range from -1 to 1 with positive value being overall positive sentiment and vice versa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test it out on a few more lines. Tweak the variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obvious Positive {'neg': 0.0, 'neu': 0.417, 'pos': 0.583, 'compound': 0.6369}\n",
      "Obvious Negative {'neg': 0.787, 'neu': 0.213, 'pos': 0.0, 'compound': -0.5719}\n",
      "Sarcastic {'neg': 0.0, 'neu': 0.633, 'pos': 0.367, 'compound': 0.7964}\n",
      "Context 1 {'neg': 0.355, 'neu': 0.645, 'pos': 0.0, 'compound': -0.6597}\n",
      "Context 2 {'neg': 0.468, 'neu': 0.532, 'pos': 0.0, 'compound': -0.6597}\n"
     ]
    }
   ],
   "source": [
    "# Obvious Postive\n",
    "postive = \"I love Professor Juett's class\"\n",
    "print(f\"Obvious Positive {analyzer.polarity_scores(postive)}\")\n",
    "\n",
    "# Obvious Negative\n",
    "negative = \"I hate EECS376\"\n",
    "print(f\"Obvious Negative {analyzer.polarity_scores(negative)}\")\n",
    "\n",
    "# Sarcasm\n",
    "sarcastic = \"Oh yes, clearly adding more meetings to my schedule is exactly what I need to boost my productivity.\"\n",
    "print(f\"Sarcastic {analyzer.polarity_scores(sarcastic)}\")\n",
    "\n",
    "# Words with different meaning in different context\n",
    "context1 = \"He was killing it at the game last week\"\n",
    "context2 = \"The math homework is killing me\"\n",
    "print(f\"Context 1 {analyzer.polarity_scores(context1)}\")\n",
    "print(f\"Context 2 {analyzer.polarity_scores(context2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
